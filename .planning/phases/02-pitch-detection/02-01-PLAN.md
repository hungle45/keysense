---
phase: 02-pitch-detection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - src/types/pitch.ts
  - src/lib/pitch/detector.ts
  - src/lib/pitch/notes.ts
  - src/lib/pitch/cents.ts
  - src/hooks/usePitchDetection.ts
  - src/components/tuner/TunerDisplay.tsx
  - src/components/tuner/NoteDisplay.tsx
  - src/components/tuner/CentsDisplay.tsx
  - src/App.tsx
autonomous: true
requirements:
  - PITCH-01
  - PITCH-02
  - PITCH-03
  - PITCH-04
  - PITCH-05
user_setup: []
must_haves:
  truths:
    - "Pitch detection runs at 30+ FPS with minimal latency"
    - "Detected frequency (Hz) is converted to musical note name (e.g., C4, G3, A#5)"
    - "High piano notes (above C5) are detected correctly despite harmonic dominance"
    - "Visual tuner shows detected note with cents deviation (sharp/flat/in-tune)"
    - "Pitch detection ignores input below calibrated noise floor threshold"
  artifacts:
    - path: "src/lib/pitch/detector.ts"
      provides: "pitchy wrapper for McLeod pitch detection"
      exports: ["PitchDetector class", "findPitch function"]
    - path: "src/lib/pitch/notes.ts"
      provides: "Frequency to note name conversion"
      exports: ["frequencyToNote function"]
    - path: "src/lib/pitch/cents.ts"
      provides: "Cents deviation calculation"
      exports: ["calculateCents function", "getCentsColor function"]
    - path: "src/hooks/usePitchDetection.ts"
      provides: "Real-time pitch detection hook"
      exports: ["usePitchDetection hook", "PitchResult type"]
    - path: "src/components/tuner/TunerDisplay.tsx"
      provides: "Main tuner UI component"
    - path: "src/App.tsx"
      provides: "App with tuner display integrated"
  key_links:
    - from: "src/hooks/usePitchDetection.ts"
      to: "src/lib/pitch/detector.ts"
      via: "import PitchDetector"
    - from: "src/hooks/usePitchDetection.ts"
      to: "src/hooks/useCalibration.ts"
      via: "reads noiseFloor from calibration"
    - from: "src/components/tuner/TunerDisplay.tsx"
      to: "src/hooks/usePitchDetection.ts"
      via: "uses usePitchDetection hook"
    - from: "src/App.tsx"
      to: "src/components/tuner/TunerDisplay.tsx"
      via: "imports and renders TunerDisplay"
---

<objective>
Implement real-time pitch detection with tuner display.

Purpose: Users can see detected musical notes with cents deviation in real-time while playing piano.

Output: Working pitch detection at 30+ FPS with visual tuner showing note name and cents.
</objective>

<execution_context>
@/Volumes/External/Users/my_mac/.config/opencode/get-shit-done/workflows/execute-plan.md
@/Volumes/External/Users/my_mac/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-pitch-detection/02-CONTEXT.md
@.planning/phases/02-pitch-detection/02-RESEARCH.md
@.planning/phases/01-audio-foundation/01-01-SUMMARY.md

Existing foundation (Phase 1):
- src/hooks/useAudioEngine.ts: AudioContext singleton, requestMicrophone, cleanup
- src/hooks/useCalibration.ts: Returns noiseFloor (dB), frequencyRange
- src/lib/constants.ts: PIANO_MIN_FREQ, PIANO_MAX_FREQ
- src/types/audio.ts: PermissionState, CalibrationResult

Key existing exports:
```typescript
// useCalibration.ts
interface CalibrationResult {
  noiseFloor: number;
  frequencyRange: { min: number; max: number };
}

// useAudioEngine.ts
function useAudioEngine(): {
  init: () => Promise<AudioContext>;
  requestMicrophone: () => Promise<{ audioContext: AudioContext; stream: MediaStream; error: Error | null }>;
  cleanup: () => void;
  isReady: boolean;
  permissionState: PermissionState;
};
```

Reference from RESEARCH.md:
- Use pitchy 4.x for McLeod pitch detection
- Clarity threshold > 0.9 filters noise
- RMS check against noise floor before pitch detection
- requestAnimationFrame for 30+ FPS loop
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install pitchy and create pitch detection library</name>
  <files>package.json, src/types/pitch.ts, src/lib/pitch/detector.ts, src/lib/pitch/notes.ts, src/lib/pitch/cents.ts</files>
  <action>
1. Run: npm install pitchy
2. Create src/types/pitch.ts:
```typescript
export interface PitchResult {
  frequency: number;
  note: string;
  octave: number;
  cents: number;
  clarity: number;
}
```
3. Create src/lib/pitch/detector.ts:
- Import PitchDetector from 'pitchy'
- Create wrapper that accepts Float32Array and sampleRate
- Return [frequency, clarity] tuple
- Use clarity > 0.9 threshold per RESEARCH.md

4. Create src/lib/pitch/notes.ts:
- NOTE_NAMES array: ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
- frequencyToNote(frequency: number, a4 = 440):
  - midiNote = 12 * log2(frequency / a4) + 69
  - round to nearest MIDI note
  - noteIndex = roundedMidi % 12
  - octave = floor(roundedMidi / 12) - 1
  - Return { note: NOTE_NAMES[noteIndex], octave }
- Per CONTEXT.md: Use sharps (C# not Db), always show octave

5. Create src/lib/pitch/cents.ts:
- calculateCents(detectedFreq: number, noteFreq: number): number
  - cents = 1200 * log2(detectedFreq / noteFreq)
  - Round to nearest integer
- getCentsColor(cents: number): string
  - abs(cents) <= 5: green (in-tune)
  - cents > 0: red (sharp)
  - cents < 0: blue (flat)
  - Per CONTEXT.md: ±5 cents = green, sharp = red, flat = blue
- formatCents(cents: number): string
  - If positive: "+N cents", if negative: "-N cents"
</action>
  <verify>npm run build passes, npx tsc --noEmit has no errors</verify>
  <done>pitch detection library created with frequency → note conversion</done>
</task>

<task type="auto">
  <name>Task 2: Create usePitchDetection hook</name>
  <files>src/hooks/usePitchDetection.ts</files>
  <action>
Create src/hooks/usePitchDetection.ts:

1. Accept audioContext and stream as parameters
2. Create AnalyserNode with fftSize = 2048
3. Create MediaStreamSource and connect to analyser
4. Initialize PitchDetector.forFloat32Array(2048)
5. Create RMS calculation function (from lib/audio/analyser.ts - reuse calculateRMS)
6. Create isAboveNoiseFloor check: rms > noiseFloor * 1.5
7. Create detection loop using requestAnimationFrame:
   - Get Float32Array from analyser.getFloatTimeDomainData
   - Check RMS against noiseFloor (passed as ref or prop)
   - If above noise floor: run detector.findPitch
   - If clarity > 0.9 and frequency in piano range (20-5000Hz):
     - Convert frequency to note using frequencyToNote
     - Calculate cents using calculateCents
     - Set pitch state
   - If below noise floor or no clear pitch: set pitch to null
8. Return { pitch: PitchResult | null, isDetecting: boolean }
9. Clean up on unmount: cancelAnimationFrame, disconnect source

Note: Noise floor should be passed as parameter or read from useCalibration hook's noiseFloor value.
</action>
  <verify>npm run build passes, TypeScript compiles</verify>
  <done>usePitchDetection hook provides real-time pitch data</done>
</task>

<task type="auto">
  <name>Task 3: Create tuner display components</name>
  <files>src/components/tuner/TunerDisplay.tsx, src/components/tuner/NoteDisplay.tsx, src/components/tuner/CentsDisplay.tsx</files>
  <action>
Create directory src/components/tuner/

1. Create src/components/tuner/NoteDisplay.tsx:
- Props: note: string, octave: number
- Display: Large note in center of screen (e.g., "C#4")
- Font: Large, bold, centered
- Per CONTEXT.md: Full screen note display in middle

2. Create src/components/tuner/CentsDisplay.tsx:
- Props: cents: number
- Display: Number with color coding
- Use getCentsColor from lib/pitch/cents.ts
- Format: "+12 cents" or "-8 cents"
- Per CONTEXT.md: ±5 cents green, sharp red, flat blue

3. Create src/components/tuner/TunerDisplay.tsx:
- Props: pitch: PitchResult | null
- If pitch is null: Show "Play a note" message (per CONTEXT.md)
- If pitch exists: Show NoteDisplay + CentsDisplay
- Layout: Note centered, cents below note
- Full screen centered layout
- Smooth transitions for real-time updates
</action>
  <verify>npm run build passes, TypeScript compiles</verify>
  <done>TunerDisplay component shows note + cents or "Play a note"</done>
</task>

<task type="auto">
  <name>Task 4: Integrate tuner into App.tsx</name>
  <files>src/App.tsx</files>
  <action>
Update src/App.tsx:

1. Import TunerDisplay from @/components/tuner/TunerDisplay
2. Import usePitchDetection from @/hooks/usePitchDetection
3. In Home screen, after microphone is enabled:
   - Call usePitchDetection with audioContext and stream
   - Render TunerDisplay with pitch result
4. Keep existing Home/Settings navigation
5. Keep existing MicrophoneButton and Settings gear icon
6. Ensure tuner only shows when isReady=true (microphone granted)
7. Pass noiseFloor from useCalibration to usePitchDetection

The tuner should appear in the center of the screen where the placeholder currently is.
</action>
  <verify>npm run build passes, npx tsc --noEmit passes</verify>
  <done>App.tsx displays tuner when microphone is enabled</done>
</task>

</tasks>

<verification>
- All 5 requirements (PITCH-01 through PITCH-05) addressed
- npm run build completes without errors
- TypeScript compilation passes
- Pitch detection uses pitchy library per RESEARCH.md
- Tuner display follows CONTEXT.md: Note + Cents format, C#4 notation, color coding
</verification>

<success_criteria>
- User can see real-time pitch detection at 30+ FPS
- Frequency converted to note name (e.g., C4, G3, A#5)
- Visual tuner shows note with cents deviation
- Pitch ignores input below noise floor
- All requirements from ROADMAP.md satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/02-pitch-detection/02-01-SUMMARY.md`
</output>
