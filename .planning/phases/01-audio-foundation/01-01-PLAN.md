---
phase: 01-audio-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - vite.config.ts
  - tsconfig.json
  - index.html
  - src/main.tsx
  - src/App.tsx
  - src/index.css
  - src/components/ui/button.tsx
  - src/components/ui/card.tsx
  - src/components/ui/progress.tsx
  - src/components/audio/MicrophoneButton.tsx
  - src/components/audio/CalibrationView.tsx
  - src/hooks/useAudioEngine.ts
  - src/hooks/useCalibration.ts
  - src/lib/audio/audio-context.ts
  - src/lib/audio/analyser.ts
  - src/lib/constants.ts
  - src/types/audio.ts
autonomous: true
requirements:
  - AUDIO-01
  - AUDIO-02
  - AUDIO-03
  - AUDIO-04
  - CALI-01
  - CALI-02
  - CALI-03
  - MOBILE-01
  - MOBILE-02
  - MOBILE-03
  - MOBILE-04

must_haves:
  truths:
    - User can tap "Enable microphone" button to grant microphone permission via browser prompt
    - AudioContext initializes successfully on button click (not on page load)
    - Microphone stream is captured and audio data is available for processing
    - AudioContext singleton prevents multiple instances (no duplicate audio)
    - User can access calibration via Settings screen
    - User can run calibration and see noise level displayed in dB within 10 seconds
    - Calibration detects and displays usable frequency range for piano
    - App functions on mobile Safari (iOS) with proper AudioContext handling
    - App functions on mobile Chrome (Android)
    - UI adapts to portrait orientation on mobile devices
    - All interactive elements have minimum 44x44px touch targets
  artifacts:
    - path: src/hooks/useAudioEngine.ts
      provides: AudioContext + microphone management hook
      exports: ['init', 'requestMicrophone', 'cleanup', 'audioContext', 'stream', 'isReady']
    - path: src/hooks/useCalibration.ts
      provides: Noise floor measurement hook
      exports: ['noiseFloor', 'frequencyRange', 'isCalibrating', 'startCalibration']
    - path: src/components/audio/MicrophoneButton.tsx
      provides: Permission request UI with states (idle/requesting/granted/denied)
      exports: ['MicrophoneButton' component]
    - path: src/components/audio/CalibrationView.tsx
      provides: Calibration UI with progress bar and dB display
      exports: ['CalibrationView' component]
    - path: src/lib/audio/audio-context.ts
      provides: AudioContext singleton
      exports: ['getAudioContext', 'createAudioContext']
    - path: src/App.tsx
      provides: Main app with 2 screens (Home + Settings)
      exports: ['App' component with routing]
  key_links:
    - from: src/components/audio/MicrophoneButton.tsx
      to: src/hooks/useAudioEngine.ts
      via: useAudioEngine hook call
      pattern: useAudioEngine
    - from: src/hooks/useCalibration.ts
      to: src/lib/audio/audio-context.ts
      via: AudioContext instance
      pattern: getAudioContext
    - from: src/components/audio/CalibrationView.tsx
      to: src/hooks/useCalibration.ts
      via: useCalibration hook
      pattern: useCalibration
---

<objective>
Set up audio foundation: microphone permission handling, AudioContext singleton, and calibration module. Users can tap "Enable microphone" to grant permission and access calibration via Settings screen.
</objective>

<context>
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/PROJECT.md
@.planning/phases/01-audio-foundation/01-CONTEXT.md
@.planning/phases/01-audio-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize Vite + React + shadcn project</name>
  <files>package.json, vite.config.ts, tsconfig.json, index.html, src/main.tsx, src/App.tsx, src/index.css</files>
  <action>
Initialize Vite + React + TypeScript project. Install shadcn/ui with button, card, progress components. Set up basic app structure with 2 screens: Home (main tuner UI) and Settings (calibration). Ensure mobile viewport meta tag in index.html. Use responsive CSS (portrait orientation) with 44px minimum touch targets per MOBILE-04.

Create src/index.css with Tailwind directives. Create src/main.tsx mounting App. Create src/App.tsx with simple state-based routing between Home and Settings screens.
  </action>
  <verify>npm run dev starts without errors, browser shows app with Home/Settings navigation</verify>
  <done>Vite + React + shadcn/ui project running with mobile-friendly responsive layout</done>
</task>

<task type="auto">
  <name>Task 2: Create AudioContext singleton and useAudioEngine hook</name>
  <files>src/lib/audio/audio-context.ts, src/lib/audio/analyser.ts, src/lib/constants.ts, src/types/audio.ts, src/hooks/useAudioEngine.ts</files>
  <action>
Create AudioContext singleton pattern in src/lib/audio/audio-context.ts using module-level variable. Create src/types/audio.ts with PermissionState type. Create src/lib/constants.ts with piano frequency constants (PIANO_MIN_FREQ=27.5, PIANO_MAX_FREQ=4186).

Create src/hooks/useAudioEngine.ts with:
- init(): creates AudioContext on user gesture (button click) per AUDIO-02
- requestMicrophone(): calls getUserMedia({ audio: true }), returns stream
- cleanup(): stops all tracks
- Singleton pattern prevents multiple AudioContext instances per AUDIO-04
- Handles permission denied state per CONTEXT.md locked decision

Use useRef for AudioContext and MediaStream persistence. Add iOS Safari AudioContext resume handling on touchstart/click events per RESEARCH.md Pattern 4.
  </action>
  <verify>Code compiles, AudioContext singleton prevents multiple instances, permission states handled</verify>
  <done>AudioContext singleton working with permission handling - ready for microphone capture</done>
</task>

<task type="auto">
  <name>Task 3: Create MicrophoneButton component</name>
  <files>src/components/audio/MicrophoneButton.tsx</files>
  <action>
Create MicrophoneButton component with:
- Button labeled "Enable microphone" per CONTEXT.md locked decision
- States: idle, requesting, granted, denied per RESEARCH.md Pattern 2
- On click: calls useAudioEngine.requestMicrophone()
- If granted: shows "Microphone enabled" and navigates to tuner (or shows ready state)
- If denied: shows help text with instructions to enable in browser settings + retry button
- 44px minimum touch target per MOBILE-04

Use shadcn/ui Button component. Handle all PermissionState types from useAudioEngine.
  </action>
  <verify>Component renders with correct button label, handles permission flow correctly</verify>
  <done>MicrophoneButton shows correct UI for each permission state with 44px touch target</done>
</task>

<task type="auto">
  <name>Task 4: Create useCalibration hook and CalibrationView component</name>
  <files>src/hooks/useCalibration.ts, src/components/audio/CalibrationView.tsx</files>
  <action>
Create src/hooks/useCalibration.ts per RESEARCH.md Pattern 3:
- startCalibration(durationMs=3000): captures audio via AnalyserNode
- Measures RMS and converts to dB per CALI-02
- Uses 90th percentile to filter outliers
- Detects usable frequency range via FFT analysis (piano range 27.5Hz-4186Hz) per CALI-03
- Returns: noiseFloor (dB), frequencyRange ({min, max} in Hz), isCalibrating

Create src/components/audio/CalibrationView.tsx:
- Settings screen per CONTEXT.md locked decision (not main screen)
- Start calibration button with 44px touch target
- During calibration: progress bar + current dB reading per UX locked decision
- After calibration: displays noise floor dB + frequency range per CALI-02/CALI-03
- Duration: 3-5 seconds per CONTEXT.md locked decision

Use shadcn/ui Progress component for progress bar.
  </action>
  <verify>Calibration runs 3-5 seconds, displays dB reading during, shows results after</verify>
  <done>Calibration module measures noise floor in dB and detects piano frequency range</done>
</task>

<task type="auto">
  <name>Task 5: Integrate all components and test permission flow</name>
  <files>src/App.tsx, src/components/audio/MicrophoneButton.tsx, src/components/audio/CalibrationView.tsx</files>
  <action>
Integrate all components in App.tsx:
- Home screen: MicrophoneButton at top, placeholder tuner display in middle, Settings gear icon top-right
- Settings screen: CalibrationView component
- Navigation: Simple state-based routing between Home/Settings

Add mobile disconnect detection per RESEARCH.md Pitfall 5:
- Listen to MediaStreamTrack 'ended' event
- Show message when mic disconnected

Add iOS AudioContext resume handling per RESEARCH.md Pattern 4:
- Resume on any touchstart/click if suspended

Ensure all interactive elements have 44px minimum touch targets per MOBILE-04.
  </action>
  <verify>App builds, permission flow works, calibration accessible via Settings, mobile works</verify>
  <done>Complete audio foundation with permission flow and calibration working on mobile</done>
</task>

</tasks>

<verification>
- npm run build completes without errors
- TypeScript compilation passes (npx tsc --noEmit)
- All 11 requirements addressed: AUDIO-01/02/03/04, CALI-01/02/03, MOBILE-01/02/03/04
- Permission button shows "Enable microphone" label per locked decision
- Calibration accessible via Settings screen per locked decision
- 44px minimum touch targets on all interactive elements
</verification>

<success_criteria>
- User can tap "Enable microphone" button to grant microphone permission via browser prompt (AUDIO-01)
- AudioContext initializes on button click, not on page load (AUDIO-02)
- Microphone stream captured via getUserMedia (AUDIO-03)
- AudioContext singleton prevents multiple instances (AUDIO-04)
- User can run calibration and see noise level in dB (CALI-01, CALI-02)
- Calibration detects piano frequency range (CALI-03)
- App works on mobile Safari (MOBILE-01) with AudioContext resume
- App works on mobile Chrome (MOBILE-02)
- UI adapts to portrait orientation (MOBILE-03)
- Touch targets are 44x44px minimum (MOBILE-04)
</success_criteria>

<output>
After completion, create .planning/phases/01-audio-foundation/01-audio-foundation-01-SUMMARY.md
</output>
